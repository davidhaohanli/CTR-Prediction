{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StackPros\n",
    "\n",
    "## Data Scientists Assessment - Coding Test\n",
    "\n",
    "<br/>\n",
    "\n",
    "<div style=\"text-align: right\"> Author: Haohan (David) Li</div>\n",
    "<div style=\"text-align: right\"> Data Source: StackPros </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: sklearn in /Users/leehh/anaconda/lib/python3.6/site-packages\n",
      "Requirement already up-to-date: scikit-learn in /Users/leehh/anaconda/lib/python3.6/site-packages (from sklearn)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already up-to-date: xgboost in /Users/leehh/anaconda/lib/python3.6/site-packages\n",
      "Requirement already up-to-date: scipy in /Users/leehh/anaconda/lib/python3.6/site-packages (from xgboost)\n",
      "Requirement already up-to-date: numpy in /Users/leehh/anaconda/lib/python3.6/site-packages (from xgboost)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#TODO comment recheck\n",
    "#TODO depensencies to top\n",
    "#TODO markdown explanation\n",
    "#TODO class reconstruction and feature complementation - especially cleaner\n",
    "#TODO merge into class\n",
    "#TODO plot unfinished\n",
    "#TODO feature selection, add more, pandas feature name\n",
    "#TODO model add more, imbalance, hyper tuning, ROC, other metrics\n",
    "\n",
    "#Dependencies Check\n",
    "!pip install sklearn --upgrade\n",
    "!pip install xgboost --upgrade\n",
    "\n",
    "#General\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import os\n",
    "import html\n",
    "\n",
    "#Feature Selection\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Preprocessing\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import binarize\n",
    "\n",
    "#Model Selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Models\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier as XG\n",
    "\n",
    "#Metrics\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "#Jupyter Notebook Magic\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Data_Loader(object):\n",
    "    \n",
    "    #which column to use as index\n",
    "    indCol = 0\n",
    "    \n",
    "    #file name\n",
    "    fileName = 'StackPros_Assessment_DataScientist_S_file.csv'\n",
    "    \n",
    "    def __init__(self, dir:str=os.getcwd()):\n",
    "        '''\n",
    "        dir: the directory keepping data source, default as current directory\n",
    "        '''\n",
    "        self.path = dir + '/' + Data_Loader.fileName\n",
    "    \n",
    "    def load(self)->pd.DataFrame:\n",
    "        '''\n",
    "        return: the data frame contains the data\n",
    "        '''\n",
    "        return pd.read_csv(self.path,index_col=Data_Loader.indCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load the data\n",
    "loader = Data_Loader()\n",
    "df = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sample and feature size\n",
    "sampleSize = df.shape[0]\n",
    "featureSize = df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sampleSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a decorator that could be used in many functions after\n",
    "def updateVarInfo(labelCol='Action',abandon = ['ID','RealTime']):\n",
    "    \n",
    "    def wrapper(func):\n",
    "\n",
    "        ContinousTypes = [np.dtype('float')]\n",
    "        ForceToContinous = ['ActionTime']\n",
    "        ForceToCat = ['BannerArea','BannerRatio']\n",
    "\n",
    "        def _wrapper(self, *args, **kwargs):\n",
    "            self.varCategories = {'ContinousVars':list(),'CategoricalVars':list(),'LabelVars':labelCol}\n",
    "            for col in self.df.columns:\n",
    "                if col!=labelCol and col not in abandon:\n",
    "                    if (self.df[col].dtype in ContinousTypes or col in ForceToContinous) and \\\n",
    "                    col not in ForceToCat:\n",
    "                        self.varCategories['ContinousVars'].append(col)\n",
    "                    else:\n",
    "                        self.varCategories['CategoricalVars'].append(col)\n",
    "            if labelCol:\n",
    "                self.labelCounts = self.df.groupby(labelCol).size()\n",
    "                \n",
    "            return func(self, *args, **kwargs)\n",
    "        return _wrapper\n",
    "    \n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis on Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class General_Analyzer(object):\n",
    "    \n",
    "    colNames = ['Data Type','Null Percentage','Variable Range or Value Count']\n",
    "    \n",
    "    def __init__(self,df:pd.DataFrame):\n",
    "        '''\n",
    "        df: the data frame to analyze\n",
    "        '''\n",
    "        self.df = df\n",
    "        \n",
    "    def null_check(self)->pd.Series:\n",
    "        '''\n",
    "        return: a report in series for null value count in percentage format\n",
    "        '''\n",
    "        return self.df.isnull().sum().apply(lambda x:str(x/self.df.shape[0]*100)[:8]+'%')\n",
    "    \n",
    "    def dtype_check(self)->pd.Series:\n",
    "        '''\n",
    "        return: a report in series for data type in each column\n",
    "        '''\n",
    "        return self.df.dtypes\n",
    "    \n",
    "    @updateVarInfo(None,[])\n",
    "    def unique_count_or_range(self)->pd.Series:\n",
    "        '''\n",
    "        return: a report in series for number of unique values in each column\n",
    "        '''\n",
    "        variables = {}\n",
    "        for col in self.df.columns:\n",
    "            if col in self.varCategories['ContinousVars']:\n",
    "                variables[col] = '{} -- {}'.format('%.5g'% self.df[col].min(),'%.5g'% self.df[col].max())\n",
    "            else:\n",
    "                variables[col] = len(self.df[col].unique())\n",
    "        return pd.Series(variables)\n",
    "        \n",
    "    def generate_report(self)->pd.Series:\n",
    "        '''\n",
    "        return: a report concate null check and data type check\n",
    "        '''\n",
    "        newDf = pd.concat((self.dtype_check(),self.null_check(),self.unique_count_or_range()),axis=1)\n",
    "        newDf.columns = General_Analyzer.colNames\n",
    "        return newDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "generalAnalyzer = General_Analyzer(df)\n",
    "generalAnalyzer.generate_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Nan_Filler(object):\n",
    "    \n",
    "    labelCol = 'Action'\n",
    "    \n",
    "    def __init__(self, df:pd.DataFrame):\n",
    "        '''\n",
    "        df: Data frame to operate\n",
    "        '''\n",
    "        self.df = df\n",
    "    \n",
    "    def getFillValByLabel(self, col:str, mode:str='mean')->dict:\n",
    "        fillVal = dict()\n",
    "        for label in self.df[Nan_Filler.labelCol].unique():\n",
    "            fillVal[label] = getattr(self.df[self.df[Nan_Filler.labelCol]==label][col],mode)()\n",
    "        return fillVal\n",
    "    \n",
    "    #TODO faster algorithm\n",
    "    def fillByLabel(self, col:str, mode:str='mean', inplace:bool=True)->pd.Series or None:\n",
    "        fillVal = self.getFillValByLabel(col,mode)\n",
    "        \n",
    "        filledCol = self.df.apply(lambda row: row[col] if not np.isnan(row[col]) \\\n",
    "                             else fillVal[row[Nan_Filler.labelCol]],axis=1)\n",
    "        \n",
    "        if not inplace:\n",
    "            return filledCol\n",
    "        else:\n",
    "            self.df[col] = filledCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nan_filler = Nan_Filler(df)\n",
    "nan_filler.fillByLabel('InteractionTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generalAnalyzer.null_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lower Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['BannerSize']=df['BannerSize'].map(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Plotter(object):\n",
    "    \n",
    "    labelCol = 'Action'\n",
    "    \n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "    \n",
    "    def canvas(self,varCat,cols=2):\n",
    "        plt.close()\n",
    "        cols = cols\n",
    "        rows = int(len(self.varCategories[varCat])/cols)+1\n",
    "        fig = plt.figure(figsize=(10,10*rows//cols))\n",
    "        return fig,cols,rows\n",
    "    \n",
    "    @updateVarInfo()\n",
    "    def continousPlot(self):\n",
    "        fig,cols,rows = self.canvas('ContinousVars')\n",
    "        for n,col in enumerate(self.varCategories['ContinousVars']):\n",
    "            ax = fig.add_subplot(rows,cols,n+1)\n",
    "            ax.set_title(col)\n",
    "            bw = (self.df[col].max()-self.df[col].min())/20\n",
    "            for label in self.df[Plotter.labelCol].unique():\n",
    "                sns.kdeplot(self.df[self.df[Plotter.labelCol]==label][col], bw=bw ,label=label)\n",
    "            plt.legend(loc='upper right')\n",
    "            plt.xticks(fontsize=10,rotation=90)\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    @updateVarInfo(None)\n",
    "    def continousSinglePlot(self):\n",
    "        fig,cols,rows = self.canvas('ContinousVars')\n",
    "        for n,col in enumerate(self.varCategories['ContinousVars']):\n",
    "            ax = fig.add_subplot(rows,cols,n+1)\n",
    "            ax.set_title(col)\n",
    "            bw = (self.df[col].max()-self.df[col].min())/20\n",
    "            sns.kdeplot(self.df[col], bw=bw, legend=False)\n",
    "            text = 'Mean: {}\\nVariance: {}'.format('%.5g'% self.df[col].mean(),'%.5g'% self.df[col].var())\n",
    "            ax.text(0.5, 0.95, text,transform=ax.transAxes, fontsize=14,verticalalignment='top')\n",
    "            plt.xticks(fontsize=10,rotation=90)\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    @updateVarInfo()\n",
    "    def catgoricalPlot(self):\n",
    "        fig,cols,rows = self.canvas('CategoricalVars')\n",
    "        for n,col in enumerate(self.varCategories['CategoricalVars']):\n",
    "            ax = fig.add_subplot(rows,cols,n+1)\n",
    "            ax.set_title(col)\n",
    "            seriesAll = []\n",
    "            colNames = []\n",
    "            for label in self.df[Plotter.labelCol].unique():\n",
    "                seriesAll.append(self.df[self.df[Plotter.labelCol]==label].groupby([col]).size()/\n",
    "                                 self.labelCounts[label])\n",
    "                colNames.append(label)\n",
    "            newDf = pd.concat(seriesAll,axis=1)\n",
    "            newDf.columns = colNames\n",
    "            newDf.plot(kind = 'bar',ax=ax)\n",
    "            plt.legend(loc='upper right')\n",
    "            plt.xticks(fontsize=10,rotation=90)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "    @updateVarInfo(None) \n",
    "    def catgoricalSinglePlot(self,mergeThreshold=0.021):\n",
    "        fig,cols,rows = self.canvas('CategoricalVars')\n",
    "        for n,col in enumerate(self.varCategories['CategoricalVars']):\n",
    "            ax = fig.add_subplot(rows,cols,n+1)\n",
    "            ax.set_title(col)\n",
    "            if col != Plotter.labelCol:\n",
    "                each = self.df[col].value_counts().to_dict()\n",
    "                SUM = sum(each.values())\n",
    "                new = {'others':0}\n",
    "                for key in each.keys():\n",
    "                    if each[key]/SUM < mergeThreshold or key == 'other':\n",
    "                        new['others'] += each[key]\n",
    "                    else:\n",
    "                        new[key] = each[key]\n",
    "                if new['others'] == 0:\n",
    "                    new.pop('others')\n",
    "                plt.pie(x=new.values(),labels=new.keys(),autopct='%1.1f%%')\n",
    "            else:\n",
    "                plt.pie(x=self.df[col].value_counts().values,labels=self.df[col].value_counts().index,\\\n",
    "                        autopct='%1.1f%%')\n",
    "            centre_circle=plt.Circle((0,0),0.7,color='white',fc='white',linewidth=1)\n",
    "            fig.gca().add_artist(centre_circle)\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = Plotter(df)\n",
    "plotter.continousSinglePlot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.catgoricalSinglePlot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotter.continousPlot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotter.catgoricalPlot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['colour'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Enigneering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getArea(size):\n",
    "    if size == 'other':\n",
    "        return np.nan\n",
    "    sizeInInt = [int(num) for num in size.split('x')]\n",
    "    return sizeInInt[0]*sizeInInt[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['BannerArea'] = df['BannerSize'].map(getArea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getRatio(size):\n",
    "    if size == 'other':\n",
    "        return np.nan\n",
    "    sizeInInt = [int(num) for num in size.split('x')]\n",
    "    return sizeInInt[0]/sizeInInt[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['BannerRatio'] = df['BannerSize'].map(getRatio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generalAnalyzer.generate_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nan_filler.fillByLabel('BannerArea')\n",
    "nan_filler.fillByLabel('BannerRatio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generalAnalyzer.null_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['RealTime'] = pd.to_datetime(df['ActionTime'], unit='us')\n",
    "df['Year'] = df['RealTime'].dt.year\n",
    "df['Month'] = df['RealTime'].dt.month\n",
    "df['Day'] = df['RealTime'].dt.day\n",
    "df['Hour'] = df['RealTime'].dt.hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['ID','ActionTime','BannerSize','RealTime'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotter.catgoricalPlot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mapHour():\n",
    "    hourMap = {'Late Night':(0,7),'Morning':(7,12),'Afternoon':(12,18),'Night':(18,24)}\n",
    "    hourMapFlipped = dict()\n",
    "    for dayRange,hourRange in hourMap.items():\n",
    "        for hour in range(*hourRange):\n",
    "            hourMapFlipped[hour] = dayRange\n",
    "    return hourMapFlipped\n",
    "\n",
    "hourMap = mapHour()\n",
    "\n",
    "df['DayRange'] = df['Hour'].map(lambda x: hourMap[x])\n",
    "\n",
    "df.drop(['Hour'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.catgoricalPlot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colToDummy = ['Website','Brand','DayRange','BannerArea','BannerRatio','Year','Month','Day']\n",
    "\n",
    "dummies = list()\n",
    "\n",
    "def getAllDummies(df):\n",
    "    for col in colToDummy:\n",
    "        dummies.append(pd.get_dummies(df[col],prefix=col))\n",
    "        \n",
    "getAllDummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encodedDf = pd.concat([df.drop(colToDummy,axis=1),*dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodedDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encodedDf['Action'] = encodedDf['Action'].map(lambda x: 1 if x=='Click' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodedDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = encodedDf['Action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = encodedDf.drop(['Action'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = .999 * (1 - .999)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "temp = scaler.fit_transform(features['InteractionTime'].values.reshape(-1,1))\n",
    "\n",
    "temp.var() > (threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = VarianceThreshold(threshold=(threshold))\n",
    "\n",
    "sel.fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unselected = dict()\n",
    "\n",
    "for i,col in enumerate(features.columns):\n",
    "    if sel.variances_[i] <= threshold and col != 'InteractionTime':\n",
    "        unselected[col] = sel.variances_[i]\n",
    "        \n",
    "unselected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features.drop(list(unselected.keys()),axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "pValues = chi2(features,labels)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unselected = dict()\n",
    "\n",
    "for i,col in enumerate(features.columns):\n",
    "    if pValues[i] >= alpha:\n",
    "        unselected[col] = sel.variances_[i]\n",
    "        \n",
    "unselected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features.drop(list(unselected.keys()),axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 18)\n",
    "features_pca = pca.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_features = normalize(features_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(final_features, labels, test_size=0.1, random_state=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Baseline Model - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrHyperParamCandidates = {'C' : np.logspace(-2,1.5,10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LR(penalty='l1', solver='liblinear', class_weight='balanced', n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(lr,lrHyperParamCandidates,scoring='roc_auc',n_jobs=1,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_best = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_thresholds = np.logspace(-4,-1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findThreshold(model,threshold):\n",
    "    pred = binarize(model.predict_proba(X_train)[:,1].reshape(-1,1),threshold)\n",
    "    f10 = fbeta_score(y_train,pred,10)\n",
    "    return f10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_threshold = 0.5 # = list(pred_thresholds)[np.argmax(np.vectorize(findThreshold)(lr_best,pred_thresholds))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proba = lr_best.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = binarize(proba.reshape(-1,1),best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f10_lr = fbeta_score(y_test,y_pred,10)\n",
    "f10_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_plot(fpr,tpr,name,auc):\n",
    "        plt.figure(figsize=(20,5))\n",
    "        plt.plot(fpr,tpr)\n",
    "        plt.ylim([0.0,1.0])\n",
    "        plt.ylim([0.0, 1.0])\n",
    "        plt.title('ROC of {}      AUC: {}'.format(name,auc))\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = roc_auc_score(y_test,proba)\n",
    "fpr, tpr, thresholds = roc_curve(y_test,proba,pos_label=1)\n",
    "roc_plot(fpr,tpr,'Logistic Regression',auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
